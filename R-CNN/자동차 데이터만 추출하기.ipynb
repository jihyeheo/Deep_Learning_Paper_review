{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASCAL VOC 2007 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\VOCtest_06-Nov-2007.tar\n",
      "Extracting ./data\\VOCtest_06-Nov-2007.tar to ./data\n",
      "{'annotation': {'folder': 'VOC2007', 'filename': '001983.jpg', 'source': {'database': 'The VOC2007 Database', 'annotation': 'PASCAL VOC2007', 'image': 'flickr', 'flickrid': '335006172'}, 'owner': {'flickrid': 'Baliwag boy', 'name': 'jojo puno'}, 'size': {'width': '500', 'height': '375', 'depth': '3'}, 'segmented': '0', 'object': [{'name': 'bus', 'pose': 'Left', 'truncated': '0', 'difficult': '0', 'bndbox': {'xmin': '61', 'ymin': '123', 'xmax': '348', 'ymax': '226'}}]}}\n",
      "(375, 500, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.datasets import VOCDetection\n",
    "\n",
    "dataset = VOCDetection('./data', year='2007',image_set='test', download=True)\n",
    "\n",
    "img, target = dataset[1000]\n",
    "img = np.array(img)\n",
    "\n",
    "print(target)\n",
    "print(img.shape)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASCAL VOC 2007 CAR 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import utils\n",
    "\n",
    "suffix_xml = '.xml'\n",
    "suffix_jpeg = '.jpg'\n",
    "\n",
    "car_test_path = './data/VOCdevkit/VOC2007/ImageSets/Main/car_test.txt'\n",
    "\n",
    "voc_annotation_dir = './data/VOCdevkit/VOC2007/Annotations/'\n",
    "voc_jpeg_dir = './data/VOCdevkit/VOC2007/JPEGImages/'\n",
    "\n",
    "car_root_dir = './data/voc_car/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_val(data_path):\n",
    "    samples = []\n",
    "\n",
    "    with open(data_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            res = line.strip().split(' ')\n",
    "            if len(res) == 3 and int(res[2]) == 1:\n",
    "                samples.append(res[0])\n",
    "\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test(samples):\n",
    "\n",
    "    length = len(samples)\n",
    "\n",
    "    random_samples = random.sample(range(length), int(length / 10))\n",
    "    # print(random_samples)\n",
    "    new_dataset = samples[random_samples]\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_car(sample_list):\n",
    "\n",
    "    car_samples = list()\n",
    "    for sample_name in sample_list:\n",
    "        annotation_path = os.path.join(voc_annotation_dir, sample_name + suffix_xml)\n",
    "        with open(annotation_path, 'rb') as f:\n",
    "            xml_dict = xmltodict.parse(f)\n",
    "            print(xml_dict)\n",
    "\n",
    "    bndboxs = list()\n",
    "    objects = xml_dict['annotation']['object']\n",
    "    if isinstance(objects, list):\n",
    "        for obj in objects:\n",
    "            obj_name = obj['name']                     \n",
    "            difficult = int(obj['difficult'])\n",
    "            if 'car'.__eq__(obj_name) and difficult != 1:\n",
    "                 car_samples.append(sample_name)\n",
    "            elif isinstance(objects, dict):\n",
    "                obj_name = objects['name']\n",
    "                difficult = int(objects['difficult'])\n",
    "            if 'car'.__eq__(obj_name) and difficult != 1:\n",
    "                car_samples.append(sample_name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return car_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_car(car_samples, data_root_dir, data_annotation_dir, data_jpeg_dir):\n",
    "\n",
    "    for sample_name in car_samples:\n",
    "        src_annotation_path = os.path.join(voc_annotation_dir, sample_name + suffix_xml)\n",
    "        dst_annotation_path = os.path.join(data_annotation_dir, sample_name + suffix_xml)\n",
    "        shutil.copyfile(src_annotation_path, dst_annotation_path)\n",
    "\n",
    "        src_jpeg_path = os.path.join(voc_jpeg_dir, sample_name + suffix_jpeg)\n",
    "        dst_jpeg_path = os.path.join(data_jpeg_dir, sample_name + suffix_jpeg)\n",
    "        shutil.copyfile(src_jpeg_path, dst_jpeg_path)\n",
    "\n",
    "    csv_path = os.path.join(data_root_dir, 'car.csv')\n",
    "    np.savetxt(csv_path, np.array(car_samples), fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_test(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = os.path.join(car_root_dir, 'test')\n",
    "data_annotation_dir = os.path.join(data_root_dir, 'Annotations')\n",
    "data_jpeg_dir = os.path.join(data_root_dir, 'JPEGImages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_car(samples, data_root_dir, data_annotation_dir, data_jpeg_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 모델별 annotation 생성 및 custom dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selectivesearch\n",
    "\n",
    "def parse_annotation_jpeg(annotation_path, jpeg_path, gs):\n",
    "\n",
    "    img = cv2.imread(jpeg_path)\n",
    "\n",
    "    selectivesearch.config(gs, img, strategy='q')\n",
    "    rects = selectivesearch.get_rects(gs) # region proposals\n",
    "    bndboxs = parse_xml(annotation_path) # ground truth boxes\n",
    "\n",
    "    # get size of the biggest bounding box(region proposals)\n",
    "    maximum_bndbox_size = 0\n",
    "    for bndbox in bndboxs:\n",
    "        xmin, ymin, xmax, ymax = bndbox\n",
    "        bndbox_size = (ymax - ymin) * (xmax - xmin)\n",
    "        if bndbox_size > maximum_bndbox_size:\n",
    "            maximum_bndbox_size = bndbox_size\n",
    "\n",
    "    # Comparing all region proposals and ground truth\n",
    "    # return a list of iou results for each region proposals\n",
    "    iou_list = compute_ious(rects, bndboxs)\n",
    "\n",
    "    positive_list = list()\n",
    "    negative_list = list()\n",
    "\n",
    "    for i in range(len(iou_list)):\n",
    "        xmin, ymin, xmax, ymax = rects[i]\n",
    "        rect_size = (ymax - ymin) * (xmax - xmin)\n",
    "\n",
    "        iou_score = iou_list[i]\n",
    "\n",
    "        # When fine-tuning the pre-trained CNN model\n",
    "        # positive : iou >= 0.5\n",
    "        # negative : iou < 0.5\n",
    "        # Only the bounding box with iou greater than 0.5 is saved\n",
    "        if iou_score >= 0.5:\n",
    "            positive_list.append(rects[i])\n",
    "\n",
    "        # negative : iou < 0.5 And if it is more than 20% of the largest bounding box\n",
    "        if 0 < iou_list[i] < 0.5 and rect_size > maximum_bndbox_size / 5.0:\n",
    "            negative_list.append(rects[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return positive_list, negative_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-u4kjpz2z\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-3cfe011451dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselectivesearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_selective_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparse_annotation_jpeg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_annotation_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_jpeg_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-8cf9857c7e77>\u001b[0m in \u001b[0;36mparse_annotation_jpeg\u001b[1;34m(annotation_path, jpeg_path, gs)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjpeg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mselectivesearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselectivesearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# region proposals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mbndboxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ground truth boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\heojihye\\soodapeaple\\Papers\\RCNN\\RCNN공부\\selectivesearch.py\u001b[0m in \u001b[0;36mconfig\u001b[1;34m(gs, img, strategy)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitchToSelectiveSearchFast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitchToSelectiveSearchQuality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-u4kjpz2z\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "gs = selectivesearch.get_selective_search()\n",
    "parse_annotation_jpeg(data_annotation_dir, data_jpeg_dir,gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
