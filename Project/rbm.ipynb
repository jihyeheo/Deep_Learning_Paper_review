{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape : (60000, 196)\n",
      "X Test Shape  (10000, 196)\n",
      "y Train Shape : (60000,)\n",
      "y Test Shape  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# mnist dataset (60000 train, 10000 test)\n",
    "# raw dataset\n",
    "train_data = pd.read_csv(\"mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"mnist_test (2).csv\")\n",
    "\n",
    "#X_train = train_data.drop([\"label\"], axis = 1).values\n",
    "#X_test = test_data.drop([\"label\"], axis = 1).values\n",
    "\n",
    "y_train = train_data.label.values\n",
    "y_test = test_data.label.values\n",
    "\n",
    "# pca (196 features)\n",
    "rbm_train = pd.read_csv('x_train_rbm.csv')\n",
    "rbm_test = pd.read_csv('x_test_rbm.csv')\n",
    "\n",
    "\n",
    "X_train = rbm_train.values\n",
    "X_test = rbm_test.values\n",
    "\n",
    "\n",
    "print(\"X Train Shape :\", X_train.shape)\n",
    "print(\"X Test Shape \", X_test.shape)\n",
    "print(\"y Train Shape :\",y_train.shape)\n",
    "print(\"y Test Shape \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1,14,14))\n",
    "X_test = X_test.reshape((-1,4,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1].reshape(14,14))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.pad(X_train, [[0, 0], [2,2], [2,2]])/255\n",
    "X_test = tf.pad(X_test, [[0, 0], [2,2], [2,2]])/255\n",
    "X_train = tf.expand_dims(X_train, axis=3, name=None)\n",
    "X_test = tf.expand_dims(X_test, axis=3, name=None)\n",
    "X_train = tf.repeat(X_train, 3, axis=3)\n",
    "X_test = tf.repeat(X_test, 3, axis=3)\n",
    "X_val = X_train[-2000:,:,:,:]\n",
    "y_val = y_train[-2000:]\n",
    "X_train = X_train[:-2000,:,:,:]\n",
    "y_train = y_train[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([58000, 18, 18, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(x,\n",
    "              filters_1x1,\n",
    "              filters_3x3_reduce,\n",
    "              filters_3x3,\n",
    "              filters_5x5_reduce,\n",
    "              filters_5x5,\n",
    "              filters_pool):\n",
    "    path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same',    activation='relu')(x)\n",
    "    path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n",
    "    path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n",
    "    path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n",
    "    return tf.concat([path1, path2, path3, path4], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = layers.Input(shape=(18, 18, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=X_train.shape[1:])(inp)\n",
    "x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "x = inception(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool=32)\n",
    "x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool=64)\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "x = inception(x, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool=64)\n",
    "aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "aux1 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n",
    "aux1 = layers.Flatten()(aux1)\n",
    "aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
    "aux1 = layers.Dropout(0.7)(aux1)\n",
    "aux1 = layers.Dense(10, activation='softmax')(aux1)\n",
    "x = inception(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "x = inception(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool=64)\n",
    "aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "aux2 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n",
    "aux2 = layers.Flatten()(aux2)\n",
    "aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
    "aux2 = layers.Dropout(0.7)(aux2) \n",
    "aux2 = layers.Dense(10, activation='softmax')(aux2)\n",
    "x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "x = inception(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool=128)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = inp, outputs = [out, aux1, aux2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "907/907 [==============================] - 2262s 2s/step - loss: 3.6832 - dense_4_loss: 2.3020 - dense_1_loss: 2.3020 - dense_3_loss: 2.3021 - dense_4_accuracy: 0.1104 - dense_1_accuracy: 0.1086 - dense_3_accuracy: 0.1091 - val_loss: 3.6831 - val_dense_4_loss: 2.3020 - val_dense_1_loss: 2.3020 - val_dense_3_loss: 2.3019 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 2/10\n",
      "907/907 [==============================] - 2255s 2s/step - loss: 3.6822 - dense_4_loss: 2.3013 - dense_1_loss: 2.3015 - dense_3_loss: 2.3014 - dense_4_accuracy: 0.1140 - dense_1_accuracy: 0.1139 - dense_3_accuracy: 0.1140 - val_loss: 3.6830 - val_dense_4_loss: 2.3019 - val_dense_1_loss: 2.3019 - val_dense_3_loss: 2.3018 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 3/10\n",
      "907/907 [==============================] - 2256s 2s/step - loss: 3.6820 - dense_4_loss: 2.3012 - dense_1_loss: 2.3013 - dense_3_loss: 2.3012 - dense_4_accuracy: 0.1117 - dense_1_accuracy: 0.1117 - dense_3_accuracy: 0.1117 - val_loss: 3.6827 - val_dense_4_loss: 2.3017 - val_dense_1_loss: 2.3017 - val_dense_3_loss: 2.3017 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 4/10\n",
      "907/907 [==============================] - 2248s 2s/step - loss: 3.6820 - dense_4_loss: 2.3013 - dense_1_loss: 2.3012 - dense_3_loss: 2.3012 - dense_4_accuracy: 0.1131 - dense_1_accuracy: 0.1131 - dense_3_accuracy: 0.1131 - val_loss: 3.6829 - val_dense_4_loss: 2.3018 - val_dense_1_loss: 2.3018 - val_dense_3_loss: 2.3018 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 5/10\n",
      "907/907 [==============================] - 2245s 2s/step - loss: 3.6821 - dense_4_loss: 2.3013 - dense_1_loss: 2.3013 - dense_3_loss: 2.3013 - dense_4_accuracy: 0.1120 - dense_1_accuracy: 0.1120 - dense_3_accuracy: 0.1120 - val_loss: 3.6830 - val_dense_4_loss: 2.3019 - val_dense_1_loss: 2.3019 - val_dense_3_loss: 2.3019 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 6/10\n",
      "907/907 [==============================] - 2250s 2s/step - loss: 3.6815 - dense_4_loss: 2.3010 - dense_1_loss: 2.3009 - dense_3_loss: 2.3009 - dense_4_accuracy: 0.1148 - dense_1_accuracy: 0.1148 - dense_3_accuracy: 0.1148 - val_loss: 3.6826 - val_dense_4_loss: 2.3016 - val_dense_1_loss: 2.3016 - val_dense_3_loss: 2.3016 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 7/10\n",
      "907/907 [==============================] - 2250s 2s/step - loss: 3.6823 - dense_4_loss: 2.3014 - dense_1_loss: 2.3014 - dense_3_loss: 2.3014 - dense_4_accuracy: 0.1125 - dense_1_accuracy: 0.1125 - dense_3_accuracy: 0.1125 - val_loss: 3.6829 - val_dense_4_loss: 2.3018 - val_dense_1_loss: 2.3018 - val_dense_3_loss: 2.3018 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 8/10\n",
      "907/907 [==============================] - 2243s 2s/step - loss: 3.6815 - dense_4_loss: 2.3009 - dense_1_loss: 2.3010 - dense_3_loss: 2.3009 - dense_4_accuracy: 0.1122 - dense_1_accuracy: 0.1122 - dense_3_accuracy: 0.1122 - val_loss: 3.6829 - val_dense_4_loss: 2.3018 - val_dense_1_loss: 2.3018 - val_dense_3_loss: 2.3018 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 9/10\n",
      "907/907 [==============================] - 2242s 2s/step - loss: 3.6824 - dense_4_loss: 2.3015 - dense_1_loss: 2.3016 - dense_3_loss: 2.3016 - dense_4_accuracy: 0.1113 - dense_1_accuracy: 0.1113 - dense_3_accuracy: 0.1113 - val_loss: 3.6830 - val_dense_4_loss: 2.3019 - val_dense_1_loss: 2.3018 - val_dense_3_loss: 2.3018 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n",
      "Epoch 10/10\n",
      "907/907 [==============================] - 2251s 2s/step - loss: 3.6818 - dense_4_loss: 2.3012 - dense_1_loss: 2.3011 - dense_3_loss: 2.3011 - dense_4_accuracy: 0.1131 - dense_1_accuracy: 0.1131 - dense_3_accuracy: 0.1131 - val_loss: 3.6828 - val_dense_4_loss: 2.3017 - val_dense_1_loss: 2.3017 - val_dense_3_loss: 2.3017 - val_dense_4_accuracy: 0.1070 - val_dense_1_accuracy: 0.1070 - val_dense_3_accuracy: 0.1070\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=[losses.sparse_categorical_crossentropy,\n",
    "                    losses.sparse_categorical_crossentropy,\n",
    "                    losses.sparse_categorical_crossentropy]\n",
    "              ,loss_weights=[1, 0.3, 0.3],\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, [y_train, y_train, y_train], validation_data=(X_val, [y_val, y_val, y_val]), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
